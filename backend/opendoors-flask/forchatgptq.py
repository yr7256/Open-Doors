@recom_bp.route('/hybrid', methods=['POST'])
def hybrid_filtering():
    try:
        topK = 10
        data = request.json # json ê°ì²´ë¥¼ ì¼ë‹¨ í†µì§¸ë¡œ ê°€ì ¸ì˜´.

        # ğŸ˜€ì—¬ê¸°ì„œë¶€í„° ì•„ë˜ë¡œ ë‹¤ì‹œ íŒŒì‹±í•˜ëŠ” ë¡œì§.
        ref_user_str = data['user']
        user_dto_str = data['users']
        spot_dto_str = data['spots']

        ref_user_dict = json.loads(ref_user_str)
        users_dict = json.loads(user_dto_str)
        spots_dict = json.loads(spot_dto_str)
        spot_info_matrix = transform_dto_to_spot_matrix(user_dto_str) # json.loadsê°€ í•„ìš”?
        spot_review_count_arr = transform_dto_to_review_count_arr(user_dto_str)
        

        spot_len = len(spots_matrix)


        spots_matrix = transform_dto_to_spot_matrix(spots_dict)
        spot_cat_arr = [spots_matrix[idx][-1] for idx in range(len(spot_info_matrix))] # ì¹´í…Œê³ ë¦¬ë§Œ ëª¨ì•„ë†“ì€ arr
        
        user_id, user_category_ids, user_facility_vector, user_coor, rating_vector, like_vector = transform_dto_to_ref_user_arrs(ref_user_dict, spot_len)
        
        
        user_id_arr, user_facility_matrix, rating_matrix, like_matrix = transform_dto_to_user_matrixes(users_dict, spot_len) # ì™„ë£Œ.
        
        
        ref_facility_arr = [0] + user_facility_vector + user_coor + [0, 0] # ë§¨ì•, ë§¨ë’¤ ë‘ê°œëŠ” postional argument ìœ„í•´ 0ìœ¼ë¡œ ë‘ .
        

        # ê³„ì‚°ë¶€
        content_based_arr, manhattan_distances, facility_scores = content_based_recom(ref_facility_arr, spot_info_matrix, category=None) # [(score/30, spotId, manhattan_dist) ... idìˆœì„œëŒ€ë¡œ ë°˜í™˜]
        user_sim_arr = colab_filtering(rating_vector, rating_matrix, like_vector, like_matrix, user_id_arr) # [(ìœ ì €ê°„ ìœ ì‚¬ë„ê°€ ë“¤ì–´ì˜´.) (userpk, ìœ ì‚¬ë„), (userpk, ìœ ì‚¬ë„)... ]
        expected_rating_arr = calc_expected_rating(user_sim_arr, rating_matrix) # [(ì˜ˆìƒì ìˆ˜, pk), (ì˜ˆìƒì ìˆ˜, pk)...] user_sim_arrëŠ” 0.3ì •ë„ë¡œ ë°˜ì˜ëœë‹¤.
        score_spotpk_category_arr = [[content_based_arr[idx][0]*3 + expected_rating_arr[idx][0], expected_rating_arr[idx][1], spot_cat_arr[idx]] for idx in range(len(expected_rating_arr))]
        filtered_spots = filtering_by_cat_list(score_spotpk_category_arr, user_category_ids)
        top10_spots = sorted(filtered_spots, reverse=True)[:topK] # pk-1ì´ indexê°€ ë¨.
        res_with_recom_reason = verify_recom_reason(top10_spots, manhattan_distances, facility_scores, expected_rating_arr, spot_review_count_arr)

        return jsonify(res_with_recom_reason)

    except ValueError as e:
        abort(400, str(e))
    except KeyError as e:
        abort(400, f'Missing key: {str(e)}')
    except Exception as e:
        abort(500, str(e))


def transform_dto_to_spot_arr(spot_dict):
    spotSfInfos = spot_dict['sfInfoIds']   # ->[1]
    spotId = spot_dict['spotId'] #-> 1
    spotLat = spot_dict['spotLat'] #-> 36.39665
    spotLng = spot_dict['spotLng'] #-> 127.4027
    reviewRating = spot_dict['reviewScore'] #-> 4.49
    reviewCount = spot_dict['reviewCount'] #-> 244
    category = spot_dict['spotCategory'] # ì‹ë‹¹ 1, ë„ì„œê´€ 31, 32 ... ğŸ˜€
    

    sfvector = binary_vectorize(spotSfInfos)
    
    return [spotId] + sfvector + [spotLat, spotLng, reviewRating, reviewCount, category]

    
    

def transform_dto_to_spot_matrix(dto_matrix):
    dto_matrix = json.loads(dto_matrix)
    return [transform_dto_to_spot_arr(spot_dict) for spot_dict in dto_matrix]




def transform_dto_to_ref_user_arrs(dto_dict, spot_matrix_length):
    user_id = dto_dict['userId']
    spotSfInfos = dto_dict['sfInfoIds']
    
    spotLat = dto_dict['userLat']
    spotLng = dto_dict['userLng']
    user_coor = [spotLat, spotLng]

    reviews_arr = dto_dict['reviews']
    like_arr = dto_dict['likeList']
    dislike_arr = dto_dict['disLikeList']
    
    category_ids = dto_dict.get('categoryIds') # ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ë“¤. ë§ˆì§€ë§‰ì— ê±¸ëŸ¬ì¤˜ì•¼í•¨. (ë‹¤ë¥¸ ëª¨ë“  ìœ ì €ë“¤ì˜ ì •ë³´ë“¤ì€ null ë“¤ì–´ì˜´.)
    

    rating_vector = create_rating_vector(reviews_arr, spot_matrix_length) # [] idx NoëŠ” pkë¥¼ ì˜ë¯¸. valueëŠ” í‰ì ì„ ì˜ë¯¸. 0ì€ ë¯¸í‰ê°€.
    like_vector = create_like_vector(like_arr, dislike_arr, spot_matrix_length) # [] idx NoëŠ” pkë¥¼ ì˜ë¯¸. valueëŠ” 1/-1 ì¢‹ì•„ìš” ì‹«ì–´ìš”ë¥¼ ì˜ë¯¸. 0ì€ ë¯¸í‰ê°€.

    user_facility_vector = binary_vectorize(spotSfInfos)

    
    return user_id, category_ids, user_facility_vector, user_coor, rating_vector, like_vector
        

def transform_dto_to_review_count_arr(dto_matrix):
    dto_matrix = json.loads(dto_matrix)
    return [spot_dict['reviewCount'] for spot_dict in dto_matrix]



def create_rating_vector(arr, spot_matrix_length):
    rating_dict = dict()
    rating_vector = np.zeros(spot_matrix_length)

    for review_item in arr:
        spotId = review_item.get('spotId')
        review_score = review_item.get('reviewScore')
        rating_dict[spotId] = review_score

    for k,v in rating_dict:
        rating_vector[k-1] = v

    return rating_vector.tolist()


def create_like_vector(like_arr, dislike_arr, spot_matrix_length):
    like_vector = np.zeros(spot_matrix_length)
    like_vector[np.array(like_arr)-1] = 1
    like_vector[np.array(dislike_arr)-1] = -1
        
    return like_vector.tolist()



def transform_dto_to_user_matrixes(user_dict_list, spot_matrix_length):
    # 
    user_facility_matrix = []
    rating_matrix = []
    like_matrix = []
    user_id_arr= []

    for idx, spot_dict in enumerate(user_dict_list):
        user_id, category_ids, user_facility_vector, user_coor, rating_vector, like_vector = transform_dto_to_ref_user_arrs(spot_dict, spot_matrix_length)
        # category_ids, user_coorì€ null, (0.0, 0.0)
        user_facility_matrix.append(user_facility_vector)
        rating_matrix.append(rating_vector)
        like_matrix.append(like_vector)
        user_id_arr.append(user_id)
    
    return user_id_arr, np.array(user_facility_matrix), np.array(rating_matrix), np.array(like_matrix)


def verify_recom_reason(recom_arr, manhattan_distances, facility_scores, expected_rating_arr, spot_review_count_arr):
    '''
    top10_spots/recom_arr -> [[ìµœì¢…ì ìˆ˜, pk, ì¹´í…Œê³ ë¦¬], [ìµœì¢…ì ìˆ˜, pk, ì¹´í…Œê³ ë¦¬], [ìµœì¢…ì ìˆ˜, pk, ì¹´í…Œê³ ë¦¬] ... ] 1ë¶€í„° ì‹œì‘
    
    manhattan_distances, facility_scores, expected_rating_arr, spot_review_count_arr  idxê°€ pkë¥¼ ëŒ€ì²´. 0ë¶€í„° ì‹œì‘.
    '''
    result = []

    for recom_item in recom_arr:
        pk = recom_item[1]
        idx = pk - 1
        
        if facility_scores[idx] > 0.7:
            result.append([recom_item, round(manhattan_distances[idx]*1000,-2), 'ë°°ë ¤ì‹œì„¤ìœ ì‚¬ë„ê°€ ë†’ì•„ìš”!'])
        elif manhattan_distances[idx] < 0.5:
            result.append([recom_item, round(manhattan_distances[idx]*1000,-2), 'ë°©ë¬¸í•˜ê¸° ì¢‹ì€ ìœ„ì¹˜ì— ìˆì–´ìš”!'])
        elif expected_rating_arr[idx] > 3.5:
            result.append([recom_item, round(manhattan_distances[idx]*1000,-2), 'ë¹„ìŠ·í•œ ì·¨í–¥ì˜ ì‚¬ìš©ìë“¤ì´ ì¶”ì²œí•œ ì¥ì†Œì—ìš”!'])
        elif spot_review_count_arr[idx] > 500:
            result.append([recom_item, round(manhattan_distances[idx]*1000,-2), 'ìš°ë¦¬ë™ë„¤ í•« í”Œë ˆì´ìŠ¤!'])
        else:
            result.append([recom_item, round(manhattan_distances[idx]*1000,-2), 'ì£¼ë³€ ì‚¬ìš©ìë“¤ì˜ í‰ê°€ê°€ ì¢‹ì€ ì¥ì†Œì—ìš”!'])

    return result


def filtering_by_cat_list(res_spots, cat_list):
    # í•„í„°ë§ arr ì´ìš©í•´ì„œ ê±°ë¥´ê³  ë°˜í™˜í•˜ëŠ” ë¡œì§

    if not cat_list: # cat_listê°€ ë¹„ì–´ìˆì„ì‹œ í•„í„°ë§ì„ ì•ˆí•˜ê³  ê·¸ëŒ€ë¡œ ë°˜í™˜
        return res_spots
    
    else:
        filtered_spots = []
        for spot in res_spots:
            if spot[2] in cat_list:
                filtered_spots.append(spot)
            else:
                pass
    
    return filtered_spots



def colab_filtering(user_rating_arr, rating_matrix, user_like_arr, like_matrix, user_id_arr):
    rating_sim_arr = rating_cos_sim(user_rating_arr, rating_matrix) # npArr
    like_sim_arr = like_cos_sim(user_like_arr, like_matrix) # npArr ì´ê±° ìˆ˜ì • í•„ìš”.

    res_sim = rating_sim_arr + like_sim_arr
    res_sim /= 2
    res_sim = res_sim.tolist()
    
    res_id_sim = list(zip(user_id_arr, res_sim))

    return res_id_sim


# rating ê¸°ì¤€ìœ¼ë¡œ í•œ ìœ ì‚¬ë„ êµ¬í•˜ê¸° 0-1
def rating_cos_sim(user_rating_arr, rating_matrix): # ë‘˜ì¤‘ í•˜ë‚˜ê°€ 0ì´ë©´, ìœ ì‚¬ë„ ë¶„ëª¨ì— ì•ˆë“¤ì–´ê°.
    print('í‰ì ìœ¼ë¡œ ìœ ì‚¬ë„ ì‹œì‘!')
    user_rating_arr = np.array(user_rating_arr).reshape(1,-1)
    res = cosine_similarity(user_rating_arr, rating_matrix)
    res[np.isnan(res)] = 0  # ë¶„ëª¨ê°€ 0ì¸ ê²½ìš° ìœ ì‚¬ë„ë¥¼ 0ìœ¼ë¡œ ì„¤ì • # ì˜µì…˜ì…ë‹ˆë‹¤.
    print('í‰ì ìœ¼ë¡œ ìœ ì‚¬ë„')
    print(res)
    return res


# like/dislike ê¸°ì¤€ìœ¼ë¡œ í•œ ìœ ì‚¬ë„ êµ¬í•˜ê¸° 0-1 # ê°€ì¤‘ì¹˜ ì¢€ ì¤„ì´ëŠ”ê²Œ ì¢‹ì„ê±°ê°™ìŒ.
def like_cos_sim(user_like_arr, like_matrix):
    print('ì¢‹ì•„ìš”/ì‹«ì–´ìš”ë¡œ ìœ ì‚¬ë„ ì‹œì‘!')
    user_like_arr = np.array(user_like_arr).reshape(1,-1)
    res = cosine_similarity(user_like_arr, like_matrix)
    res[np.isnan(res)] = 0  # ë¶„ëª¨ê°€ 0ì¸ ê²½ìš° ìœ ì‚¬ë„ë¥¼ 0ìœ¼ë¡œ ì„¤ì • # ì˜µì…˜ì…ë‹ˆë‹¤.
    print('ì¢‹ì•„ìš”,ì‹«ì–´ìš”ë¡œ ìœ ì‚¬ë„')
    print(res)

    return res


def calc_expected_rating(user_sim_arr, rating_matrix):
    # í–‰ë ¬ì˜ í¬ê¸° ê³„ì‚°
    num_users, num_spots = rating_matrix.shape
    
    # ì˜ˆìƒ í‰ì ì„ ì €ì¥í•  ë°°ì—´ ìƒì„±
    expected_ratings = np.zeros(num_spots)
    
    # ê¸°ì¤€ ìœ ì €ì™€ ë‹¤ë¥¸ ìœ ì €ë“¤ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì´ìš©í•˜ì—¬ ì˜ˆìƒ í‰ì  ê³„ì‚°
    for user_pk, sim in user_sim_arr:
        user_idx = user_pk - 1
        ratings = rating_matrix[user_idx]
        rated_spots = np.nonzero(ratings)[0]  # í‰ì ì„ ë§¤ê¸´ ì‹œì„¤ì˜ ì¸ë±ìŠ¤ë“¤
        sim_matrix = np.ones(num_spots) * sim  # ìœ ì‚¬ë„ë¡œ ì´ë£¨ì–´ì§„ í–‰ë ¬
        numerator = sim_matrix[rated_spots] @ ratings[rated_spots]  # ë¶„ì ê³„ì‚°
        denominator = sim_matrix[rated_spots].sum()  # ë¶„ëª¨ ê³„ì‚°
        if denominator > 0:
            expected_ratings[rated_spots] += numerator / denominator
    
    return expected_ratings.tolist()


def content_based_recom(ref_arr, spot_matrix, category=None):
    # ref_arr = [1, 1,0,0,0,0,0,0,0, 36.3965, 127.4027, 4.49, 244]

    cat_col_num = 13 # ë§¨ ë§ˆì§€ë§‰ì— ë¼ì›Œë„£ì„ê²ƒì„.
    # spot_matrixì˜ catì´ 1(ì¹´í˜)ì¸ ê³³ë“¤ë§Œ ì„ íƒ
    spot_df = pd.DataFrame(spot_matrix)

    ref_spotId = ref_arr[0]
    ref_facility_arr = ref_arr[1:9]
    ref_coor = ref_arr[9:11]
    ref_rating = ref_arr[11:13]

    # ì¹´í…Œê³ ë¦¬ì˜ ì •ë³´ê°€ ì¼ì¹˜í•˜ëŠ” rowë§Œ ì‚´ë¦° df
    if category != None: # ì¹´í…Œê³ ë¦¬ì— 0ë„ ìˆìŒ.
        cat_filtered_df = spot_df.loc[spot_df.iloc[:, cat_col_num] == category, :]
    else:
        cat_filtered_df = spot_df

    facility_spotIds = cat_filtered_df.iloc[:, :1]
    facility_spotIds = [item[0] for item in facility_spotIds.values.tolist()] # nested listë¡œ ë°›ì•„ì˜¨ê±¸ arrë¡œ ë³€í™˜
    
    facility_df = cat_filtered_df.iloc[:, 1:9]
    coor_df = cat_filtered_df.iloc[:, 9:11]
    rating_df = cat_filtered_df.iloc[:, 11:13]
    matrix_size = len(facility_spotIds)
    
    # 1ì°¨ - ì‹œì„¤ ìœ ì‚¬ë„ì •ë³´ êµ¬í•¨. ndArr.
    facility_scores = facility_cos_sim(ref_facility_arr, facility_df) # 0-10ì˜ ìŠ¤ì½”ì–´ê°€ ë‚˜ì˜¨ë‹¤.
    manhattan_distances = [manhattan_distance(ref_coor, coor_item) for coor_item in coor_df.itertuples(index=False)]
    manhattan_scores = convert_manhattan_distances(manhattan_distances) # 0-10ì˜ ìŠ¤ì½”ì–´ê°€ ë‚˜ì˜¨ë‹¤.
    rating_scores = [rating_score(*rating) for rating in rating_df.itertuples(index=False)] # 0-10ì˜ ìŠ¤ì½”ì–´ê°€ ë‚˜ì˜¨ë‹¤.
    scores_sum = sum_scores(facility_scores, manhattan_scores, rating_scores) # 0-30ì˜ ìŠ¤ì½”ì–´ê°€ ë‚˜ì˜¨ë‹¤.
    score_id_mapped_list = [(score/30, spotId, manhattan_dist) for score, spotId, manhattan_dist in zip(scores_sum, facility_spotIds, manhattan_distances)] # 
    return score_id_mapped_list, manhattan_distances, facility_scores
    



def binary_vectorize(arr):
    # 8ê°œì§œë¦¬ vector ë°°ì—´ë§Œë“¬
    bin_vector = np.zeros(8)
    bin_vector[np.array(arr)-1] = 1
    return bin_vector


# ê±°ë¦¬ê³„ì‚° 1 - ë§¨í•˜íƒ„ê±°ë¦¬
def manhattan_distance(coor_A, coor_B):
    a_lng, a_lat = coor_A
    b_lng, b_lat = coor_B
    coor_midpoint = [b_lng, a_lat]

    lng_dist = haversine(coor_A, coor_midpoint)
    lat_dist = haversine(coor_B, coor_midpoint)
    
    # ë§¨í•˜íƒ„ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    sum_distance = lng_dist + lat_dist
    return sum_distance



def convert_manhattan_distances(manhattan_distances):
    result = []

    for distance in manhattan_distances:
        if distance < 0.5:  # 0.5 km ë¯¸ë§Œì¸ ê²½ìš°
            single_score = 10
        elif distance > 10:  # 10 km ì´ˆê³¼ì¸ ê²½ìš°
            single_score = 0
        else:  # 0.5 km ì´ìƒ 10 km ì´í•˜ì¸ ê²½ìš°
            single_score = ((1 - (distance - 0.5) / 9.5)*10)
        
        result.append(single_score)
    return result


# ì‹œì„¤ ìœ ì‚¬ë„ arrë¡œ ë°˜í™˜, idx ìœ ì§€
def facility_cos_sim(ref_facility_arr, facility_matrix):
    ref_facility_arr = np.array(ref_facility_arr).reshape(1,-1)
    res = cosine_similarity(ref_facility_arr, facility_matrix)
    # print(type(res))
    # print(res)
    return res[0]


# ê°€ì¤‘ì¹˜ ì¡°ì ˆ ì¶”í›„ì— ì§„í–‰
def rating_score(avg_score, count):
    score_weight = 1
    count_weight = 1

    return (avg_score*score_weight + log10(count)*count_weight)


def sum_scores(facility_scores, manhattan_scores, rating_scores):
    return [sum(score_tuple) for score_tuple in zip(facility_scores, manhattan_scores, rating_scores)]
